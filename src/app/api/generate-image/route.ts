// src/app/api/generate-image/route.ts
// API route to generate images using GPT-4o for description and Hugging Face for image generation
// ÙŠØ¯Ø¹Ù… ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙØŒ Ø§Ù„ØªØ±Ø¬Ù…Ø©ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©

import { NextRequest, NextResponse } from 'next/server';
import { AIAPIGateway } from '@/lib/api';
import { gptGodModels, huggingFaceModels, openRouterModels, AIModel } from '@/lib/models';
import { saveImageAsBase64, saveImageAsFile, saveImageWithResponsive } from '@/utils/saveImage';
import { validateImageBlob, validateImageRequest, validateImage } from '@/utils/validateImage';
import { generateResponsive, extractImageMetadata } from '@/utils/generateResponsive';
import { 
  imageGenerationLimiter, 
  enhancePromptLimiter, 
  getClientIdentifier, 
  createRateLimitResponse 
} from '@/utils/rateLimiter';

/**
 * Helper function to create consistent response headers
 */
function createResponseHeaders(options: {
  cacheControl?: string;
  rateLimit?: { remaining: number; resetTime: number };
} = {}) {
  const headers: Record<string, string> = {
    'Content-Type': 'application/json'
  };
  
  if (options.cacheControl) {
    headers['Cache-Control'] = options.cacheControl;
  }
  
  if (options.rateLimit) {
    headers['X-RateLimit-Remaining'] = options.rateLimit.remaining.toString();
    headers['X-RateLimit-Reset'] = options.rateLimit.resetTime.toString();
  }
  
  return headers;
}

/**
 * POST /api/generate-image
 * ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT-4o Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØµÙ + Hugging Face Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
 * Generate images using GPT-4o for description + Hugging Face for actual image generation
 */
export async function POST(request: NextRequest) {
  try {
    // ğŸ›¡ï¸ Rate limiting - Check if client is within allowed limits
    const clientId = getClientIdentifier(request);
    const rateLimit = imageGenerationLimiter.isAllowed(clientId);
    
    if (!rateLimit.allowed) {
      console.log(`ğŸš« Rate limit exceeded for client: ${clientId}`);
      return createRateLimitResponse(
        rateLimit.remaining, 
        rateLimit.resetTime,
        'Too many image generation requests. Please wait before trying again | Ø·Ù„Ø¨Ø§Øª ÙƒØ«ÙŠØ±Ø© Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰'
      );
    }
    
    const body = await request.json();
    const { 
      prompt,
      model = "black-forest-labs/FLUX.1-dev", // Default HF image model
      size = "1024x1024",
      quality = "standard",
      useGPT4Description = false, // Ø®ÙŠØ§Ø± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ - Ù…Ø¹Ø·Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
      descriptionModel = "gpt-4o-mini", // Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ (Ø£ÙˆÙØ± Ù…Ù† gpt-4o)
      enhanceOnly = false, // Ø®ÙŠØ§Ø± Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©
      translateOnly = false // Ø®ÙŠØ§Ø± Ù„ØªØ±Ø¬Ù…Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙÙ‚Ø·
    } = body;

    if (!prompt) {
      return NextResponse.json(
        { 
          error: 'Prompt is required | Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ø·Ù„ÙˆØ¨'
        }, 
        { 
          status: 400,
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );
    }

    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø·Ù„Ø¨
    const validation = validateImageRequest(prompt, model);
    if (!validation.isValid) {
      return NextResponse.json(
        { 
          error: validation.error
        }, 
        { 
          status: 400,
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );
    }

    console.log(`Generating image with prompt: "${prompt}"`);
    console.log(`Using model: ${model}, Description enhancement: ${useGPT4Description ? descriptionModel : 'disabled'}`);

    const aiGateway = new AIAPIGateway();
    let finalPrompt = prompt;
    let gptDescription = null;
    let usedDescriptionModel = null;

    // Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØ­Ø³ÙŠÙ† ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    if (useGPT4Description) {
      try {
        console.log(`Using ${descriptionModel} to enhance image description...`);
        
        // Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
        let selectedModel = [...gptGodModels, ...openRouterModels, ...huggingFaceModels].find((m: AIModel) => m.id === descriptionModel);
        
        // fallback Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        if (!selectedModel) {
          console.warn(`Model ${descriptionModel} not found, trying alternatives...`);
          selectedModel = gptGodModels.find((m: AIModel) => m.id === 'gpt-4o-mini') || 
                        gptGodModels.find((m: AIModel) => m.id === 'gpt-3.5-turbo') ||
                        gptGodModels.find((m: AIModel) => m.id === 'gpt-4o');
        }
        
        if (!selectedModel) {
          throw new Error(`Description model not found: ${descriptionModel}`);
        }

        usedDescriptionModel = selectedModel;

        // Ø·Ù„Ø¨ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ Ø£Ùˆ Ø§Ù„ØªØ±Ø¬Ù…Ø©
        let systemPrompt = '';
        let userContent = '';
        
        if (translateOnly) {
          systemPrompt = 'You are a professional Arabic-English translator. Translate the Arabic text to natural, accurate English while preserving the meaning, tone, and context. Provide only the English translation without explanations.';
          userContent = prompt;
        } else {
          systemPrompt = '';
          userContent = `Enhance this image description for better AI image generation. Make it detailed and vivid but concise. Original: "${prompt}"`;
        }

        const messages = translateOnly ? [
          {
            role: 'system' as const,
            content: systemPrompt
          },
          {
            role: 'user' as const,
            content: userContent
          }
        ] : [
          {
            role: 'user' as const,
            content: userContent
          }
        ];

        const enhancedDescription = await aiGateway.sendMessage(messages, selectedModel);

        gptDescription = enhancedDescription;
        finalPrompt = enhancedDescription.trim();
        console.log(`Enhanced description from ${selectedModel.name}:`, finalPrompt);

        // Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ ÙÙ‚Ø·ØŒ Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù‡Ù†Ø§
        if (enhanceOnly) {
          // Use more lenient rate limit for text enhancement
          const enhanceRateLimit = enhancePromptLimiter.isAllowed(clientId);
          
          return NextResponse.json({
            success: true,
            finalPrompt: finalPrompt,
            originalPrompt: prompt,
            descriptionModel: selectedModel.name,
            model: selectedModel.id,
            provider: selectedModel.provider,
            type: 'enhancement'
          }, {
            headers: createResponseHeaders({
              cacheControl: 'no-cache, must-revalidate',
              rateLimit: enhanceRateLimit
            })
          });
        }
        
      } catch (enhancementError: any) {
        console.warn(`${descriptionModel} enhancement failed, using original prompt:`, enhancementError.message);
        // Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù€ prompt Ø§Ù„Ø£ØµÙ„ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        usedDescriptionModel = null;
      }
    }

    // Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Ù…ÙˆØ°Ø¬ Hugging Face
    const imageModel = huggingFaceModels.find((m: AIModel) => m.id === model);
    if (!imageModel || !imageModel.capabilities.includes('text_to_image')) {
      return NextResponse.json(
        { 
          error: `Model ${model} not found or doesn't support image generation | Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ø£Ùˆ Ù„Ø§ ÙŠØ¯Ø¹Ù… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±`
        }, 
        { 
          status: 400,
          headers: {
            'Content-Type': 'application/json'
          }
        }
      );
    }

    // Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Hugging Face
    try {
      console.log('Generating actual image with Hugging Face...');
      
      const imageBlob = await aiGateway.generateImageHF(finalPrompt, model);
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©
      const blobValidation = validateImageBlob(imageBlob);
      if (!blobValidation.isValid) {
        return NextResponse.json(
          { 
            error: blobValidation.error || 'Invalid generated image | ØµÙˆØ±Ø© Ù…ÙˆÙ„Ø¯Ø© ØºÙŠØ± ØµØ­ÙŠØ­Ø©'
          }, 
          { 
            status: 400,
            headers: {
              'Content-Type': 'application/json'
            }
          }
        );
      }
      
      // Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ¨Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£ÙØ¶Ù„
      try {
        // ØªØ­Ø¯ÙŠØ¯ Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        const extension = imageBlob.type === 'image/jpeg' ? 'jpg' : 
                         imageBlob.type === 'image/webp' ? 'webp' : 'png';
        
        // ØªØ­ÙˆÙŠÙ„ Blob Ø¥Ù„Ù‰ Buffer
        const arrayBuffer = await imageBlob.arrayBuffer();
        const buffer = Buffer.from(arrayBuffer);
        
        const savedImage = await saveImageWithResponsive(buffer, extension);
        
        // Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        const imageMetadata = extractImageMetadata(`data:${savedImage.contentType};base64,${buffer.toString('base64')}`);

        // Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø© JSON Ù…Ø±ØªØ¨Ø© Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ¨Ø©
        return NextResponse.json({
          success: true,
          url: savedImage.filePath,
          srcset: savedImage.responsive.srcSet,
          sizes: "(max-width: 600px) 100vw, 600px",
          alt: "Generated AI Image",
          prompt: prompt,
          finalPrompt: finalPrompt,
          gptDescription: gptDescription,
          model: imageModel.name,
          provider: 'Hugging Face',
          type: 'image',
          enhanced: useGPT4Description && gptDescription !== null,
          descriptionModel: usedDescriptionModel ? usedDescriptionModel.name : null,
          metadata: {
            originalPrompt: prompt,
            enhancedPrompt: finalPrompt,
            imageModel: model,
            descriptionModel: usedDescriptionModel ? usedDescriptionModel.id : null,
            size: size,
            generatedAt: new Date().toISOString(),
            imageSize: savedImage.size,
            contentType: savedImage.contentType,
            fileName: savedImage.fileName,
            imageMetadata: imageMetadata
          }
        }, {
          headers: createResponseHeaders({
            cacheControl: 'public, max-age=86400, s-maxage=86400',
            rateLimit: rateLimit
          })
        });
      } catch (validationError: any) {
        console.error('ğŸ”’ Image validation failed:', validationError.message);
        return NextResponse.json(
          { 
            error: validationError.message || 'Invalid image format or size | ØªÙ†Ø³ÙŠÙ‚ Ø£Ùˆ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± ØµØ­ÙŠØ­'
          }, 
          { 
            status: 400,
            headers: {
              'Content-Type': 'application/json'
            }
          }
        );
      }

    } catch (hfError: any) {
      console.error('Hugging Face image generation failed:', hfError);
      
      // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Hugging Face
      if (hfError.message?.includes('401') || hfError.message?.includes('unauthorized')) {
        return NextResponse.json(
          { 
            error: 'Invalid Hugging Face token | Ù…ÙØªØ§Ø­ Hugging Face ØºÙŠØ± ØµØ­ÙŠØ­'
          }, 
          { 
            status: 401,
            headers: {
              'Content-Type': 'application/json'
            }
          }
        );
      }

      // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø·Ø£ 402 - Payment Required
      if (hfError.message?.includes('402') || hfError.message?.includes('payment') || hfError.message?.includes('billing')) {
        return NextResponse.json(
          { 
            error: 'Hugging Face subscription required | ÙŠØªØ·Ù„Ø¨ Ø§Ø´ØªØ±Ø§Ùƒ Hugging Face Ù…Ø¯ÙÙˆØ¹'
          }, 
          { 
            status: 402,
            headers: {
              'Content-Type': 'application/json'
            }
          }
        );
      }

      if (hfError.message?.includes('503') || hfError.message?.includes('model') || hfError.message?.includes('loading')) {
        return NextResponse.json(
          { 
            error: 'Model loading error | Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬'
          }, 
          { 
            status: 503,
            headers: {
              'Content-Type': 'application/json'
            }
          }
        );
      }

      // Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Hugging Face - Ø¹Ø±Ø¶ Ø§Ù„ÙˆØµÙ Ø§Ù„Ù†ØµÙŠ ÙƒØ¨Ø¯ÙŠÙ„
      if (gptDescription) {
        let fallbackMessage = 'Image generation failed but got enhanced description | ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ù„ÙƒÙ† ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙˆØµÙ Ù…Ø­Ø³Ù†';
        
        // Ø±Ø³Ø§Ù„Ø© Ø®Ø§ØµØ© Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø±ØµÙŠØ¯
        if (hfError.message?.includes('exceeded') || hfError.message?.includes('credits')) {
          fallbackMessage = 'Hugging Face monthly credits exceeded. Using GPT-4o description instead | Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø±ØµÙŠØ¯ Ø§Ù„Ø´Ù‡Ø±ÙŠ Ù„Ù€ Hugging FaceØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØµÙ GPT-4o Ø¨Ø¯Ù„Ø§Ù‹';
        }

        return NextResponse.json({
          success: false,
          error: 'Image generation failed, returning description | ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©ØŒ ØªÙ… Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙˆØµÙ',
          text: gptDescription,
          prompt: prompt,
          model: 'GPT-4o (Text Description)',
          provider: 'GodGPT',
          type: 'text',
          fallback: true,
          message: fallbackMessage,
          creditsExceeded: hfError.message?.includes('exceeded') || hfError.message?.includes('credits')
        });
      }

      throw hfError;
    }

  } catch (error: any) {
    console.error('Error in image generation pipeline:', error);
    return NextResponse.json(
      {
        error: error.message || 'Internal server error | Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù…'
      },
      { 
        status: 500,
        headers: {
          'Content-Type': 'application/json'
        }
      }
    );
  }
}
